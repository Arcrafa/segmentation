wcgpu06.fnal.gov
GPU 0: Tesla V100-PCIE-32GB (UUID: GPU-bbb41574-bf7b-19b0-80b2-1d057d6f5039)
/wclustre/nova/users/rafaelma2/venv385/bin/python
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/transformers/models/maskformer/image_processing_maskformer.py:419: FutureWarning: The `reduce_labels` argument is deprecated and will be removed in v4.27. Please use `do_reduce_labels` instead.
  warnings.warn(
/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at facebook/mask2former-swin-tiny-coco-instance were not used when initializing Mask2FormerForUniversalSegmentation: ['model.pixel_level_module.decoder.encoder.layers.2.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.relative_position_index', 'model.transformer_module.decoder.layers.4.final_layer_norm.bias', 'model.transformer_module.decoder.layers.4.fc2.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.attention_weights.bias', 'model.pixel_level_module.decoder.encoder.layers.5.fc1.bias', 'model.transformer_module.decoder.layers.6.fc1.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.value.bias', 'model.pixel_level_module.decoder.encoder.layers.4.final_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.output_proj.weight', 'model.transformer_module.decoder.layers.2.self_attn.k_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.value.bias', 'model.transformer_module.decoder.layers.5.self_attn_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.4.fc2.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_after.weight', 'model.transformer_module.decoder.layers.8.cross_attn.out_proj.bias', 'model.transformer_module.decoder.layers.8.cross_attn.in_proj_weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.intermediate.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_after.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.relative_position_index', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_before.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.value.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.attention_weights.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.relative_position_bias_table', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.output.dense.weight', 'model.transformer_module.decoder.layers.2.cross_attn.in_proj_bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.key.weight', 'model.transformer_module.decoder.layers.6.fc2.weight', 'model.transformer_module.decoder.layers.3.self_attn.k_proj.weight', 'model.transformer_module.decoder.layers.7.cross_attn.in_proj_bias', 'model.pixel_level_module.decoder.encoder.layers.2.fc1.bias', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.key.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_after.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.intermediate.dense.weight', 'model.transformer_module.decoder.layers.7.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.value.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.value_proj.bias', 'model.transformer_module.decoder.layers.3.self_attn.v_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.relative_position_bias_table', 'model.transformer_module.decoder.layers.4.self_attn.v_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.sampling_offsets.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_after.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.intermediate.dense.bias', 'model.transformer_module.decoder.layers.3.cross_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.intermediate.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.relative_position_index', 'model.transformer_module.decoder.layers.3.self_attn.out_proj.weight', 'model.transformer_module.decoder.layers.3.final_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.2.fc2.weight', 'model.transformer_module.decoder.layers.7.final_layer_norm.bias', 'model.transformer_module.decoder.layers.2.cross_attn.out_proj.weight', 'model.transformer_module.decoder.layers.8.self_attn.v_proj.weight', 'model.transformer_module.decoder.layers.4.self_attn.k_proj.bias', 'model.transformer_module.decoder.layers.6.self_attn.out_proj.weight', 'model.transformer_module.decoder.layers.4.cross_attn.in_proj_bias', 'model.transformer_module.decoder.layers.7.fc2.weight', 'model.pixel_level_module.decoder.encoder.layers.3.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.value.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_after.weight', 'model.transformer_module.decoder.layers.4.fc1.weight', 'model.transformer_module.decoder.layers.6.self_attn.v_proj.bias', 'model.transformer_module.decoder.layers.7.cross_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.4.self_attn.q_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.output_proj.weight', 'model.transformer_module.decoder.layers.2.cross_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.2.self_attn.q_proj.bias', 'model.transformer_module.decoder.layers.6.final_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.4.final_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.5.fc1.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.relative_position_bias_table', 'model.transformer_module.decoder.layers.3.final_layer_norm.bias', 'model.transformer_module.decoder.layers.5.self_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.output.dense.weight', 'model.transformer_module.decoder.layers.4.cross_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.4.self_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.4.self_attn.v_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.query.bias', 'model.transformer_module.decoder.layers.5.fc1.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.output.dense.weight', 'model.transformer_module.decoder.layers.6.self_attn.k_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.query.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.key.bias', 'model.transformer_module.decoder.layers.7.self_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.7.fc1.bias', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.sampling_offsets.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_after.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.output.dense.bias', 'model.transformer_module.decoder.layers.5.self_attn.k_proj.bias', 'model.transformer_module.decoder.layers.6.fc1.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_after.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.relative_position_index', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.output_proj.weight', 'model.transformer_module.decoder.layers.2.fc2.bias', 'model.transformer_module.decoder.layers.7.cross_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.7.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.output.dense.bias', 'model.transformer_module.decoder.layers.4.cross_attn.out_proj.bias', 'model.transformer_module.decoder.layers.5.fc1.bias', 'model.transformer_module.decoder.layers.8.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.query.weight', 'model.pixel_level_module.decoder.encoder.layers.3.fc1.bias', 'model.transformer_module.decoder.layers.3.cross_attn.in_proj_weight', 'model.transformer_module.decoder.layers.7.cross_attn.in_proj_weight', 'model.transformer_module.decoder.layers.4.self_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.relative_position_bias_table', 'model.pixel_level_module.decoder.encoder.layers.4.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_after.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.intermediate.dense.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.output_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.value.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_before.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.output.dense.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.value_proj.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.output_proj.bias', 'model.transformer_module.decoder.layers.5.self_attn.q_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.key.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_before.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.output.dense.weight', 'model.transformer_module.decoder.layers.4.cross_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.query.bias', 'model.transformer_module.decoder.layers.3.cross_attn_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.8.self_attn.q_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.intermediate.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.value.bias', 'model.transformer_module.decoder.layers.2.final_layer_norm.bias', 'model.transformer_module.decoder.layers.6.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.query.bias', 'model.pixel_level_module.decoder.encoder.layers.4.fc1.weight', 'model.transformer_module.decoder.layers.5.self_attn.v_proj.bias', 'model.transformer_module.decoder.layers.7.self_attn.k_proj.weight', 'model.transformer_module.decoder.layers.5.self_attn.q_proj.bias', 'model.transformer_module.decoder.layers.8.self_attn.out_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.sampling_offsets.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_after.bias', 'model.transformer_module.decoder.layers.7.self_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.8.fc1.weight', 'model.transformer_module.decoder.layers.3.self_attn.q_proj.bias', 'model.transformer_module.decoder.layers.5.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.key.weight', 'model.transformer_module.decoder.layers.8.final_layer_norm.weight', 'model.transformer_module.decoder.layers.5.cross_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.2.self_attn.q_proj.weight', 'model.transformer_module.decoder.layers.3.self_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.6.self_attn.q_proj.weight', 'model.transformer_module.decoder.layers.3.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.intermediate.dense.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.attention_weights.bias', 'model.transformer_module.decoder.layers.3.cross_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.5.cross_attn.in_proj_bias', 'model.transformer_module.decoder.layers.8.cross_attn.out_proj.weight', 'model.transformer_module.decoder.layers.2.cross_attn.in_proj_weight', 'model.transformer_module.decoder.layers.2.fc2.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.attention_weights.bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.intermediate.dense.bias', 'model.transformer_module.decoder.layers.7.self_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.value.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.query.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.query.bias', 'model.transformer_module.decoder.layers.2.self_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.output.dense.bias', 'model.transformer_module.decoder.layers.4.fc2.bias', 'model.transformer_module.decoder.layers.3.self_attn.q_proj.weight', 'model.transformer_module.decoder.layers.4.cross_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.key.weight', 'model.pixel_level_module.decoder.encoder.layers.5.final_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.output.dense.bias', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.output_proj.bias', 'model.transformer_module.decoder.layers.2.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.key.bias', 'model.transformer_module.decoder.layers.5.self_attn.v_proj.weight', 'model.transformer_module.decoder.layers.6.self_attn.out_proj.bias', 'model.transformer_module.decoder.layers.3.fc2.weight', 'model.transformer_module.decoder.layers.3.self_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.key.bias', 'model.transformer_module.decoder.layers.7.self_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_before.bias', 'model.transformer_module.decoder.layers.3.cross_attn.in_proj_bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.intermediate.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_before.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.query.weight', 'model.transformer_module.decoder.layers.7.cross_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_after.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_before.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.key.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.query.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.sampling_offsets.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.output.dense.weight', 'model.transformer_module.decoder.layers.5.final_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.value_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.relative_position_bias_table', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_before.weight', 'model.transformer_module.decoder.layers.3.self_attn.v_proj.bias', 'model.transformer_module.decoder.layers.6.self_attn.k_proj.weight', 'model.transformer_module.decoder.layers.6.fc2.bias', 'model.transformer_module.decoder.layers.8.self_attn.k_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.key.bias', 'model.transformer_module.decoder.layers.4.self_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.3.fc2.bias', 'model.transformer_module.decoder.layers.2.fc1.weight', 'model.transformer_module.decoder.layers.5.cross_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_before.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.attention_weights.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.2.self_attn.out_proj.bias', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn_layer_norm.weight', 'model.transformer_module.decoder.layers.2.cross_attn.out_proj.bias', 'model.transformer_module.decoder.layers.8.self_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.query.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.value.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.query.weight', 'model.transformer_module.decoder.layers.6.final_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.output.dense.bias', 'model.transformer_module.decoder.layers.7.self_attn.k_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.value.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.attention_weights.weight', 'model.transformer_module.decoder.layers.4.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.intermediate.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.output.dense.bias', 'model.transformer_module.decoder.layers.6.cross_attn_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.3.fc1.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_before.bias', 'model.transformer_module.decoder.layers.8.fc1.bias', 'model.transformer_module.decoder.layers.4.fc1.bias', 'model.transformer_module.decoder.layers.6.cross_attn.in_proj_bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.value.weight', 'model.pixel_level_module.decoder.encoder.layers.3.fc2.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.relative_position_bias_table', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.value.bias', 'model.transformer_module.decoder.layers.2.self_attn.k_proj.weight', 'model.transformer_module.decoder.layers.8.cross_attn.in_proj_bias', 'model.transformer_module.decoder.layers.2.fc1.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.value.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.relative_position_index', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.key.weight', 'model.pixel_level_module.decoder.encoder.layers.4.fc1.bias', 'model.transformer_module.decoder.layers.8.self_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.5.fc2.weight', 'model.transformer_module.decoder.layers.7.cross_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.relative_position_bias_table', 'model.transformer_module.decoder.layers.4.self_attn.k_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_before.bias', 'model.transformer_module.decoder.layers.8.cross_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.query.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.output.dense.weight', 'model.pixel_level_module.decoder.encoder.layers.3.final_layer_norm.bias', 'model.transformer_module.decoder.layers.2.cross_attn_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.2.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.output.dense.weight', 'model.transformer_module.decoder.layers.4.self_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.query.bias', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.sampling_offsets.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn.value_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.5.self_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.relative_position_index', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.output.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.intermediate.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_before.weight', 'model.transformer_module.decoder.layers.8.final_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.value.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_before.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.sampling_offsets.bias', 'model.transformer_module.decoder.layers.8.fc2.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.output.dense.bias', 'model.transformer_module.decoder.layers.6.cross_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_before.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.output.dense.weight', 'model.transformer_module.decoder.layers.8.self_attn.v_proj.bias', 'model.transformer_module.decoder.layers.6.cross_attn.out_proj.bias', 'model.transformer_module.decoder.layers.7.self_attn.q_proj.bias', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_before.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.intermediate.dense.weight', 'model.transformer_module.decoder.layers.2.self_attn_layer_norm.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.query.bias', 'model.transformer_module.decoder.layers.6.cross_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.output.dense.weight', 'model.transformer_module.decoder.layers.3.cross_attn.out_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.output.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.output.dense.weight', 'model.transformer_module.decoder.layers.8.self_attn.k_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.intermediate.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.output.dense.weight', 'model.transformer_module.decoder.layers.5.cross_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.output.dense.weight', 'model.pixel_level_module.decoder.encoder.layers.5.fc2.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.key.weight', 'model.transformer_module.decoder.layers.3.fc1.weight', 'model.pixel_level_module.decoder.encoder.layers.5.fc2.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_after.bias', 'model.transformer_module.decoder.layers.4.cross_attn.in_proj_weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.intermediate.dense.bias', 'model.transformer_module.decoder.layers.2.self_attn.v_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_after.bias', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.sampling_offsets.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.value.bias', 'model.transformer_module.decoder.layers.6.self_attn.v_proj.weight', 'model.transformer_module.decoder.layers.7.self_attn.v_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.key.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_after.weight', 'model.pixel_level_module.encoder.encoder.layers.0.blocks.1.intermediate.dense.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.value_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.sampling_offsets.bias', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.value_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.value_proj.bias', 'model.transformer_module.decoder.layers.5.self_attn.k_proj.weight', 'model.transformer_module.decoder.layers.6.cross_attn.in_proj_weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.key.weight', 'model.pixel_level_module.decoder.encoder.layers.2.final_layer_norm.bias', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.attention_weights.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.key.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_after.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_after.bias', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.output_proj.weight', 'model.pixel_level_module.decoder.encoder.layers.2.fc1.weight', 'model.pixel_level_module.decoder.encoder.layers.3.self_attn.value_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.query.bias', 'model.transformer_module.decoder.layers.5.self_attn.out_proj.weight', 'model.transformer_module.decoder.layers.6.self_attn.q_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.output.dense.bias', 'model.transformer_module.decoder.layers.8.cross_attn_layer_norm.bias', 'model.transformer_module.decoder.layers.5.cross_attn.in_proj_weight', 'model.transformer_module.decoder.layers.5.self_attn.out_proj.bias', 'model.transformer_module.decoder.layers.7.self_attn.v_proj.weight', 'model.transformer_module.decoder.layers.2.self_attn.out_proj.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.output.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_after.weight', 'model.transformer_module.decoder.layers.2.self_attn.v_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.output.dense.weight', 'model.transformer_module.decoder.layers.3.self_attn.k_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.relative_position_index', 'model.transformer_module.decoder.layers.8.self_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.value.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_before.bias', 'model.transformer_module.decoder.layers.8.self_attn.q_proj.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.relative_position_index', 'model.transformer_module.decoder.layers.7.fc1.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.relative_position_bias_table', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.query.weight', 'model.transformer_module.decoder.layers.4.self_attn.q_proj.bias', 'model.transformer_module.decoder.layers.5.cross_attn_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.key.bias', 'model.pixel_level_module.decoder.encoder.layers.5.final_layer_norm.weight', 'model.transformer_module.decoder.layers.3.fc1.bias', 'model.pixel_level_module.decoder.encoder.layers.2.self_attn.attention_weights.weight', 'model.transformer_module.decoder.layers.7.self_attn.q_proj.weight', 'model.transformer_module.decoder.layers.6.self_attn_layer_norm.weight', 'model.pixel_level_module.decoder.encoder.layers.4.self_attn.output_proj.bias', 'model.pixel_level_module.decoder.encoder.layers.3.final_layer_norm.weight', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.5.intermediate.dense.bias', 'model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.output.dense.weight', 'model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_before.bias', 'model.transformer_module.decoder.layers.5.fc2.bias']
- This IS expected if you are initializing Mask2FormerForUniversalSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Mask2FormerForUniversalSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-tiny-coco-instance and are newly initialized because the shapes did not match:
- model.transformer_module.queries_embedder.weight: found shape torch.Size([100, 256]) in the checkpoint and torch.Size([30, 256]) in the model instantiated
- model.transformer_module.queries_features.weight: found shape torch.Size([100, 256]) in the checkpoint and torch.Size([30, 256]) in the model instantiated
- class_predictor.weight: found shape torch.Size([81, 256]) in the checkpoint and torch.Size([6, 256]) in the model instantiated
- class_predictor.bias: found shape torch.Size([81]) in the checkpoint and torch.Size([6]) in the model instantiated
- criterion.empty_weight: found shape torch.Size([81]) in the checkpoint and torch.Size([6]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/work1/nova/grohmc/conda/envs/nascvn/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/work1/nova/grohmc/conda/envs/nascvn/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/memory_profiler.py", line 1351, in <module>
    exec_with_profiler(script_filename, prof, args.backend, script_args)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/memory_profiler.py", line 1252, in exec_with_profiler
    exec(compile(f.read(), filename, 'exec'), ns, ns)
  File "bigo.py", line 42, in <module>
    best, others = big_o.big_o(predict, positive_int_generator, n_repeats=10,min_n=1,max_n=500, n_measures=20)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/big_o/big_o.py", line 166, in big_o
    ns, time = measure_execution_time(func, data_generator,
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/big_o/big_o.py", line 60, in measure_execution_time
    measurements = timer.repeat(n_timings, n_repeats)
  File "/work1/nova/grohmc/conda/envs/nascvn/lib/python3.8/timeit.py", line 205, in repeat
    t = self.timeit(number)
  File "/work1/nova/grohmc/conda/envs/nascvn/lib/python3.8/timeit.py", line 177, in timeit
    timing = self.inner(it, self.timer)
  File "<timeit-src>", line 6, in inner
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/big_o/big_o.py", line 53, in __call__
    return func(self.data)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/memory_profiler.py", line 609, in f
    with self.call_on_stack(func, *args, **kwds) as result:
  File "/work1/nova/grohmc/conda/envs/nascvn/lib/python3.8/contextlib.py", line 113, in __enter__
    return next(self.gen)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/memory_profiler.py", line 624, in call_on_stack
    yield func(*args, **kwds)
  File "bigo.py", line 36, in predict
    predictions = trainer.predict(model, dataloader, return_predictions=False)
  File "/wclustre/nova/users/rafaelma2/venv385/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 799, in predict
    raise TypeError(
TypeError: `Trainer.predict()` requires a `LightningModule` when it hasn't been passed in a previous run
Loaded 118 images.
mprof: Sampling memory every 0.1s
running new process
running as a Python program...
Using last profile data.
